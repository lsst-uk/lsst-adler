{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee33e193",
   "metadata": {},
   "source": [
    "# This notebook is very much work in progress with different attempts and bits to be integrated together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7ae6c-3d28-4b5c-8d6a-9fc4d9dda70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:06:02.572156Z",
     "iopub.status.busy": "2025-11-03T14:06:02.571870Z",
     "iopub.status.idle": "2025-11-03T14:06:03.137042Z",
     "shell.execute_reply": "2025-11-03T14:06:03.136222Z",
     "shell.execute_reply.started": "2025-11-03T14:06:02.572133Z"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "\n",
    "import warnings\n",
    "\n",
    "from adler.objectdata.AdlerPlanetoid import AdlerPlanetoid\n",
    "\n",
    "from adler.science.AvgMagModel import AvgMagModel\n",
    "from adler.science.PhaseCurve import PhaseCurve\n",
    "\n",
    "from adler.objectdata.Observations import Observations\n",
    "from adler.objectdata.MPCORB import MPCORB\n",
    "from adler.objectdata.SSObject import SSObject\n",
    "from adler.objectdata.AdlerData import (\n",
    "    AdlerData,\n",
    "    FilterDependentAdler,\n",
    "    AdlerSourceFlags,\n",
    "    VALID_AVG_MAG_MODELS,\n",
    "    VALID_PHASE_MODELS,\n",
    ")\n",
    "from adler.objectdata.objectdata_utilities import get_data_table, get_from_table, mpc_file_preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filter_colors_white_background = {\n",
    "    \"u\": \"#1600ea\",\n",
    "    \"g\": \"#31de1f\",\n",
    "    \"r\": \"#b52626\",\n",
    "    \"i\": \"#370201\",\n",
    "    \"z\": \"#ba52ff\",\n",
    "    \"y\": \"#61a2b3\",\n",
    "}\n",
    "plot_symbols = {\"u\": \"o\", \"g\": \"^\", \"r\": \"v\", \"i\": \"s\", \"z\": \"*\", \"y\": \"p\"}\n",
    "plot_linestyles = {\n",
    "    \"u\": \"--\",\n",
    "    \"g\": (0, (3, 1, 1, 1)),\n",
    "    \"r\": \"-.\",\n",
    "    \"i\": \"-\",\n",
    "    \"z\": (0, (3, 1, 1, 1, 1, 1)),\n",
    "    \"y\": \":\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f2e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_filepath = \"/home/astro-sobrien/\"\n",
    "# root_filepath = \"/Volumes/astro-sobrien/home/astro-sobrien/\"\n",
    "# root_filepath = \"/Users/seanobrien/Documents/Adler/\"\n",
    "current_path = os.getcwd()\n",
    "root_filepath = current_path.split(\"lsst-adler\")[0]\n",
    "\n",
    "# mpc_test_db_filename = f\"{root_filepath}lsst-adler/tests/data/mpc_obs_sbn_testing_database.sqlite\"\n",
    "# rubin_sql_filename_oct = f\"{root_filepath}rubin_251002.sqlite\"\n",
    "# rubin_sql_filename_nov = f\"{root_filepath}rubin_251105.sqlite\"\n",
    "# rubin_sql_filename_nov2 = f\"{root_filepath}rubin_251111.sqlite\"\n",
    "# rubin_sql_filename_nov3 = f\"{root_filepath}rubin_251115.sqlite\"\n",
    "\n",
    "input_sql_file = f\"{root_filepath}lsst-adler/tests/data/mpc_obs_sbn_testing_database.sqlite\"\n",
    "schema = \"MPC\"\n",
    "\n",
    "# input_sql_file = f\"{root_filepath}lsst-adler/tests/data/testing_database.db\"\n",
    "# schema = 'dp03_catalogs_10yr'\n",
    "input_conn = sqlite3.connect(input_sql_file)\n",
    "input_cur = input_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a852848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from astropy.time import Time\n",
    "\n",
    "log_timestamp = Time.now().isot.replace(\":\", \"_\")\n",
    "\n",
    "# --- Reset logging system (important for Jupyter) ---\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# --- Configure root logger to log only to a file ---\n",
    "logging.basicConfig(\n",
    "    filename=f\"{root_filepath}/adler_test_logs/adler_test_{log_timestamp}.log\",\n",
    "    filemode=\"w\",\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.DEBUG,  # capture INFO, DEBUG, etc.\n",
    ")\n",
    "\n",
    "# Optional confirmation\n",
    "logging.getLogger().info(f\"Root logging configured to write to {root_filepath}adler_test{log_timestamp}.log\")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aadce0",
   "metadata": {},
   "source": [
    "# Attempt to consolidate things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import adler.utilities.science_utilities as sci_utils\n",
    "import math\n",
    "\n",
    "\n",
    "# Set column to use for magnitude (we don't currently have reduced_mag populated for MPC file format)\n",
    "mag_col = \"reduced_mag\"\n",
    "magErr_col = \"magErr\"\n",
    "\n",
    "# Set filter list (only ugri present currently, very few u, but keeping in for completeness)\n",
    "# filter_list=['u', 'g', 'r', 'i', 'z', 'y']\n",
    "filter_list = [\"g\", \"r\"]\n",
    "\n",
    "make_plots = True\n",
    "\n",
    "if schema == \"MPC\":\n",
    "    min_obstime_mjd = math.floor(\n",
    "        pd.read_sql_query(f\"SELECT MIN(mjd_tai) FROM obs_sbn\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "    max_obstime_mjd = math.ceil(\n",
    "        pd.read_sql_query(f\"SELECT MAX(mjd_tai) FROM obs_sbn\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "elif schema == \"dp03_catalogs_10yr\":\n",
    "    min_obstime_mjd = math.floor(\n",
    "        pd.read_sql_query(f\"SELECT MIN(midPointMjdTai) FROM diaSource\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "    max_obstime_mjd = math.ceil(\n",
    "        pd.read_sql_query(f\"SELECT MAX(midPointMjdTai) FROM diaSource\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "else:\n",
    "    print(\"Schema not recognised\")\n",
    "    raise ValueError(\"Schema not recognised\")\n",
    "\n",
    "print(min_obstime_mjd)\n",
    "print(max_obstime_mjd)\n",
    "\n",
    "from astropy.stats import sigma_clip as astropy_sigma_clip\n",
    "\n",
    "sig_clip_val = 3\n",
    "\n",
    "# Set thresholds for magnitude changes\n",
    "# diff_cuts_arr = np.array([1, 2, 3])\n",
    "# std_cuts_arr = np.array([5, 6])\n",
    "# Shifting to single thresholds and recording the res value to simplify things. User can always check their own threshold if it's higher than these (or run the code themselves at a lower threshold)\n",
    "diff_cut = 1.5\n",
    "std_cut = 5\n",
    "\n",
    "# Defines how many nights of data to retrieve in total\n",
    "# By default we take the previous 30 nights and the previous 7 nights to allow different checks for outliers\n",
    "data_timespan_arr = np.array([30, 7])\n",
    "\n",
    "# Defines how many nights to consider as \"new observations\" allowing for the checking of \"sustained outliers/outbursts\"\n",
    "n_new_nights_arr = np.array([1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2452f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"----------------------------------------\")\n",
    "logger.info(\"New loop started\")\n",
    "logger.info(\"----------------------------------------\")\n",
    "\n",
    "if schema == \"MPC\":\n",
    "    process_mjd_arr = np.array([60799.5])\n",
    "    model_name = \"median\"\n",
    "elif schema == \"dp03_catalogs_10yr\":\n",
    "    process_mjd_arr = np.array([61590.5])\n",
    "    # model_name = \"HG12_Pen16\" #Not currently all working for PhaseCurves\n",
    "    model_name = \"median\"\n",
    "else:\n",
    "    raise ValueError(\"Schema not recognised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for process_mjd in process_mjd_arr: #option to loop through multiple days\n",
    "process_mjd = process_mjd_arr[0]\n",
    "start_of_night_mjd = process_mjd - 1\n",
    "\n",
    "if schema == \"MPC\":\n",
    "    obj_df = pd.read_sql_query(\n",
    "        f\"SELECT DISTINCT provid FROM obs_sbn WHERE mjd_tai BETWEEN '{start_of_night_mjd}' AND '{process_mjd}'\",\n",
    "        input_conn,\n",
    "    )\n",
    "    unique_obj_ids = obj_df.provid.to_numpy()\n",
    "elif schema == \"dp03_catalogs_10yr\":\n",
    "    obj_df = pd.read_sql_query(\n",
    "        f\"SELECT DISTINCT ssObjectId FROM diaSource WHERE midPointMjdTai BETWEEN '{start_of_night_mjd}' AND '{process_mjd}'\",\n",
    "        input_conn,\n",
    "    )\n",
    "    unique_obj_ids = obj_df.ssObjectId.to_numpy()\n",
    "else:\n",
    "    print(\"Schema not recognised\")\n",
    "    raise ValueError(\"Schema not recognised\")\n",
    "\n",
    "logger.info(f\"{len(unique_obj_ids)} objects to analyze\")\n",
    "\n",
    "if len(unique_obj_ids) == 0:\n",
    "    logger.info(f\"No objects to process for {process_mjd}\")\n",
    "    raise ValueError(f\"No objects to process for {process_mjd}\")\n",
    "    # continue\n",
    "\n",
    "output_dir = f\"outputs_consolidated_{schema}_{process_mjd}\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_db = f\"{output_dir}/adler_output.sqlite\"\n",
    "\n",
    "# Remove the output DB if it exists\n",
    "# TODO probably remove this once testing done?\n",
    "if os.path.exists(output_db):\n",
    "    os.remove(output_db)\n",
    "\n",
    "for ssObjectId in tqdm(unique_obj_ids, desc=f\"Objects to process for {process_mjd}\"):\n",
    "    for data_timespan in data_timespan_arr:\n",
    "        planetoid = AdlerPlanetoid.construct_from_mpc_obs_sbn(\n",
    "            ssObjectId=ssObjectId,\n",
    "            sql_filename=input_sql_file,\n",
    "            filter_list=filter_list,\n",
    "            date_range=[process_mjd - data_timespan, process_mjd],\n",
    "        )\n",
    "\n",
    "        for filt in planetoid.filter_list:\n",
    "            df_obs = sci_utils.get_df_obs_filt(planetoid, filt=filt)\n",
    "\n",
    "            err_flag = df_obs.magErr.isnull().all()\n",
    "            if err_flag:\n",
    "                logger.info(\"All magErr values are NaNs, proceed with caution\")\n",
    "            else:\n",
    "                # Remove observations with large errorbars\n",
    "                magErr_mask = sci_utils.large_magErr_mask(df_obs)\n",
    "                df_obs = df_obs[magErr_mask]\n",
    "\n",
    "            for n_new_nights in n_new_nights_arr:\n",
    "                # Set the modelId here, described by the bare minimum information for replication (I hope)\n",
    "                planetoid.AdlerData.modelId = (\n",
    "                    f\"{ssObjectId}_{process_mjd:.1f}_{data_timespan}n_{n_new_nights}n_{model_name}\"\n",
    "                )\n",
    "                # Split into previous observations and observations from the most recent night(s)\n",
    "                df_obs_old, df_obs_new, *_ = sci_utils.split_obs(\n",
    "                    df_obs, process_mjd=process_mjd, n_new_nights=n_new_nights\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"Previous observations (date < {}): {}\".format(\n",
    "                        process_mjd - n_new_nights, len(df_obs_old)\n",
    "                    )\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"New observations ({} <= date < {}): {}\".format(\n",
    "                        process_mjd - n_new_nights, process_mjd, len(df_obs_new)\n",
    "                    )\n",
    "                )\n",
    "                if len(df_obs_old) < 2:\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "                if len(df_obs_new) == 0:\n",
    "                    logger.info(f\"No new observations in {filt}, continuing to next band/object\")\n",
    "                    continue\n",
    "\n",
    "                # Sigma clip old observations\n",
    "                sig_clip_mask = astropy_sigma_clip(df_obs_old[mag_col], sigma=sig_clip_val).mask\n",
    "                df_obs_old = df_obs_old[~sig_clip_mask].copy()\n",
    "                if len(df_obs_old) < 2:\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations after sigma clipping, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Populate summary AdlerData params for this filter and particular model\n",
    "                ad_params = {}\n",
    "                ad_params[\"phaseAngle_min\"] = np.amin(df_obs_old[\"phaseAngle\"])  # * u.d\n",
    "                ad_params[\"phaseAngle_range\"] = np.ptp(df_obs_old[\"phaseAngle\"])  # * u.d\n",
    "                ad_params[\"observationTime_max\"] = np.amax(df_obs_old[\"midPointMjdTai\"])  # * u.d\n",
    "                ad_params[\"arc\"] = np.ptp(df_obs_old[\"midPointMjdTai\"])  # * u.d\n",
    "                ad_params[\"nobs\"] = len(df_obs_old)\n",
    "                ad_params[\"modelFitMjd\"] = Time.now().mjd\n",
    "\n",
    "                # Fit model\n",
    "                if model_name in VALID_AVG_MAG_MODELS:\n",
    "                    model = AvgMagModel().InitModelObs(\n",
    "                        mag=df_obs_old[mag_col], magErr=df_obs_old[magErr_col], model_name=model_name\n",
    "                    )\n",
    "                    ad_params.update(model.__dict__)  # store model values in ad_params\n",
    "                    planetoid.AdlerData.populate_avg_mag_parameters(filt, **ad_params)\n",
    "\n",
    "                    res = np.array(df_obs_new[mag_col]) - model.avg_mag\n",
    "                elif model_name in VALID_PHASE_MODELS:\n",
    "                    # TODO once SSObject is populated we can take the absolute magnitude from there as the initial guess (this is not currently the case for the MPC obs_sbn file)\n",
    "                    model = PhaseCurve(H=np.amin(df_obs_old[\"reduced_mag\"]) * u.mag, model_name=model_name)\n",
    "                    pc_fit = model.FitModel(\n",
    "                        phase_angle=np.array(df_obs_old[\"phaseAngle\"]) * u.deg,\n",
    "                        reduced_mag=np.array(df_obs_old[\"reduced_mag\"]) * u.mag,\n",
    "                        mag_err=np.array([df_obs_old[magErr_col]]) * u.mag,\n",
    "                    )\n",
    "                    model = model.InitModelSbpy(pc_fit)\n",
    "                    ad_params.update(model.__dict__)  # store model values in ad_params\n",
    "                    planetoid.AdlerData.populate_phase_parameters(filt, **ad_params)\n",
    "\n",
    "                    res = np.array(df_obs_new[mag_col]) - model.ReducedMag(df_obs_new[\"phaseAngle\"])\n",
    "                else:\n",
    "                    logger.error(f\"Model '{model_name}' not recognised\")\n",
    "                    raise ValueError(f\"Model '{model_name}' not recognised\")\n",
    "\n",
    "                filter_index = planetoid.AdlerData.filter_list.index(filt)\n",
    "\n",
    "                # Check for individual outlying observations\n",
    "                # Simple magnitude difference\n",
    "                diff_cut_outlier_arr = sci_utils.outlier_diff(res, diff_cut=diff_cut)\n",
    "                df_obs_new[\"mag_diff\"] = np.zeros(shape=len(df_obs_new), dtype=float)\n",
    "                df_obs_new.loc[diff_cut_outlier_arr, \"mag_diff\"] = res[diff_cut_outlier_arr]\n",
    "                planetoid.AdlerData.filter_dependent_values[filter_index].n_outlier = np.count_nonzero(\n",
    "                    diff_cut_outlier_arr\n",
    "                )\n",
    "                source_flags_obj = AdlerSourceFlags.construct_from_data_table(\n",
    "                    planetoid.ssObjectId,\n",
    "                    filt,\n",
    "                    planetoid.AdlerData.modelId,\n",
    "                    df_obs_new.loc[diff_cut_outlier_arr],\n",
    "                )\n",
    "                source_flags_obj.write_flags_to_database(output_db)\n",
    "                # I've written a populate_source_flags function that integrates these into the AdlerData.FilterDependentAdler.source_flags list\n",
    "                # planetoid.AdlerData.populate_source_flags(filt, planetoid.AdlerData.modelId, df_obs_new.loc[diff_cut_outlier_arr])\n",
    "\n",
    "                # TODO std_diff\n",
    "                # Sigma_diff check looking for how many uncertainties a given point is from the model\n",
    "                # Need to figure out the terminology, the check will be using science_utilities.outlier_sigma_diff\n",
    "\n",
    "                # Sustained outburst checks\n",
    "                # TODO how will sustained checks work with PhaseCurve models\n",
    "\n",
    "                # Identify timegaps in case there's only one night of new data (in the case where we select >1 new night)\n",
    "                df_obs_new.sort_values(by=\"midPointMjdTai\", inplace=True)\n",
    "                time_gaps = sci_utils.apparition_gap_finder(df_obs_new.midPointMjdTai.to_numpy(), dx=0.5)\n",
    "                if len(time_gaps) == 0:\n",
    "                    # If there is only one night of new data, we continue to the next band/object\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of nights with new observations, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Sigma clip new observations\n",
    "                sig_clip_mask_new = astropy_sigma_clip(df_obs_new[mag_col], sigma=sig_clip_val).mask\n",
    "                df_obs_new = df_obs_new[~sig_clip_mask_new].copy()\n",
    "\n",
    "                if len(df_obs_new) == 0:\n",
    "                    logger.info(\n",
    "                        f\"No new observations in {filt} after sigma clipping, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Calculate average magnitude of the new observations (slightly obtuse to use the model here but future proofing maybe)\n",
    "                new_obs_model = AvgMagModel().InitModelObs(\n",
    "                    mag=df_obs_new[mag_col], magErr=df_obs_new[magErr_col], model_name=model_name\n",
    "                )\n",
    "                mag_change = np.abs(new_obs_model.avg_mag - model.avg_mag)\n",
    "                # Difference in magnitude space\n",
    "                sustained_diff_cut_flag = mag_change > diff_cut\n",
    "                # Check if sustained outlier detected and record the different between the old and new avg_mag values in AdlerData\n",
    "                if sustained_diff_cut_flag:\n",
    "                    planetoid.AdlerData.filter_dependent_values[filter_index].sustained_outlier = mag_change\n",
    "                else:\n",
    "                    logger.info(f\"No sustained outlier detected\")\n",
    "\n",
    "                # TODO sustained difference in sigma space\n",
    "\n",
    "                # Write out summary AdlerData information\n",
    "                # TODO should this also have an option to write out source_flags instead of the call above so it's a one-liner?\n",
    "                planetoid.AdlerData.write_row_to_database(output_db, write_model_data=False)\n",
    "\n",
    "                # TODO make optional plotting routine into a function\n",
    "                if make_plots:\n",
    "                    # Up-to-date for the mag_diff/sustained_mag_diff checks\n",
    "                    # Identify any outliers detected\n",
    "                    # tmp_master_outlier_flag = (diff_cut_outlier_arr) | (std_cut_outlier_arr)\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.errorbar(\n",
    "                        df_obs_old[\"midPointMjdTai\"],\n",
    "                        df_obs_old[mag_col],\n",
    "                        df_obs_old[magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\".\",\n",
    "                        color=\"k\",\n",
    "                        label=\"Previous observations\",\n",
    "                    )\n",
    "                    ax.errorbar(\n",
    "                        df_obs_new[\"midPointMjdTai\"],\n",
    "                        df_obs_new[mag_col],\n",
    "                        df_obs_new[magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\".\",\n",
    "                        color=\"c\",\n",
    "                        label=\"New observations\",\n",
    "                    )\n",
    "                    ax.errorbar(\n",
    "                        df_obs_new[diff_cut_outlier_arr][\"midPointMjdTai\"],\n",
    "                        df_obs_new[diff_cut_outlier_arr][mag_col],\n",
    "                        df_obs_new[diff_cut_outlier_arr][magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\"x\",\n",
    "                        color=\"b\",\n",
    "                        label=\"Outliers\",\n",
    "                    )\n",
    "                    ax.axhline(model.avg_mag, c=\"k\", ls=\"-\")\n",
    "                    ax.axhline(new_obs_model.avg_mag, c=\"c\", ls=\"--\")\n",
    "                    ax.invert_yaxis()\n",
    "                    ax.set_xlabel(\"Time [MJD]\")\n",
    "                    ax.set_ylabel(f\"{filt}-band Reduced Magnitude\")\n",
    "                    fig.savefig(\n",
    "                        f\"{output_dir}/{planetoid.AdlerData.modelId}_{filt}_outliers.png\",\n",
    "                        bbox_inches=\"tight\",\n",
    "                        pad_inches=0.05,\n",
    "                    )\n",
    "                    plt.close(fig)\n",
    "\n",
    "# TODO Function for summary stats of all outliers detected across all objects\n",
    "# TODO multi-band outliers identified in this step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8d638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd9bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6f945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a40a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63805a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68297cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7b769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae072f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456beb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417cb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_obj_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = \"2025 MX40\"\n",
    "planetoid = AdlerPlanetoid.construct_from_mpc_obs_sbn(\n",
    "    ssObjectId=obj_id,\n",
    "    sql_filename=input_sql_file,\n",
    "    filter_list=filter_list,\n",
    "    date_range=[process_mjd - data_timespan, process_mjd],\n",
    ")\n",
    "\n",
    "adler_data = AdlerData(obj_id, planetoid.filter_list)\n",
    "\n",
    "filt = \"r\"\n",
    "df_obs = sci_utils.get_df_obs_filt(planetoid, filt=filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AvgMagModel().InitModelObs(mag=df_obs.reduced_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfca76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9336461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc57bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fad6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0dd6e8e",
   "metadata": {},
   "source": [
    "# Expanded format:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031582a",
   "metadata": {},
   "source": [
    "TODO new format:\n",
    "\n",
    "(run for night in night but once scripted it will be provided with a given night)\n",
    "\n",
    "include flag for MPC vs DP0.3 (for testing)\n",
    "\n",
    "for object in objects:\n",
    "    for filt in filters:\n",
    "        for n_new_nights in [1,3,7]:\n",
    "            sigma clip old observations, calculate median\n",
    "            check for 1/2/3 mag outliers\n",
    "            check for 3/4/5 sigma outliers\n",
    "\n",
    "\n",
    "calculate summary stats;\n",
    "N objects with outliers\n",
    "N outliers\n",
    "distribution of outliers per object and per filter\n",
    "\n",
    "other things to consider:\n",
    "consecutive outliers trigger in sigma space as an additional check? (i.e. are 95% of the new points outliers)\n",
    "are the outliers consistent across multiple filters\n",
    "minimum number of data points (different for different checks)\n",
    "minimum number of nights (different for different checks)\n",
    "if path to database that exists is provided then populate AdlerData and outliers (from AdlerSourceFlags) during processing and write to/update this database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a3a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days of data to retrieve (i.e. previous 30 nights)\n",
    "data_timespan = 30\n",
    "\n",
    "from tqdm import tqdm\n",
    "import adler.utilities.science_utilities as sci_utils\n",
    "import math\n",
    "\n",
    "\n",
    "# Set column to use for magnitude (we don't currently have reduced_mag populated for MPC file format)\n",
    "mag_col = \"reduced_mag\"\n",
    "magErr_col = \"magErr\"\n",
    "\n",
    "# Set filter list (only ugri present currently, very few u, but keeping in for completeness)\n",
    "filter_list = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "# filter_list=['g', 'r', 'i']\n",
    "\n",
    "make_plots = True\n",
    "\n",
    "if schema == \"MPC\":\n",
    "    min_obstime_mjd = math.floor(\n",
    "        pd.read_sql_query(f\"SELECT MIN(mjd_tai) FROM obs_sbn\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "    max_obstime_mjd = math.ceil(\n",
    "        pd.read_sql_query(f\"SELECT MAX(mjd_tai) FROM obs_sbn\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "elif schema == \"dp03_catalogs_10yr\":\n",
    "    min_obstime_mjd = math.floor(\n",
    "        pd.read_sql_query(f\"SELECT MIN(midPointMjdTai) FROM diaSource\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "    max_obstime_mjd = math.ceil(\n",
    "        pd.read_sql_query(f\"SELECT MAX(midPointMjdTai) FROM diaSource\", input_conn).iloc[0].values[0]\n",
    "    )\n",
    "else:\n",
    "    print(\"Schema not recognised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84728ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clip as astropy_sigma_clip\n",
    "\n",
    "sig_clip_val = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds for magnitude changes\n",
    "diff_cuts_arr = np.array([1, 2, 3])\n",
    "# std_cuts_arr = np.array([3, 4, 5])\n",
    "std_cuts_arr = np.array([5, 6])\n",
    "\n",
    "# Defines how many nights to consider as \"new observations,\" allowing for the checking of \"sustained outliers/outbursts\"\n",
    "n_new_nights_arr = np.array([1, 3, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined the strings that will be used as column headers and populated later\n",
    "night_mag_string = \"outlier_{}night_mag\"\n",
    "night_std_string = \"outlier_{}night_sigma\"\n",
    "\n",
    "outlier_cols_list = []\n",
    "for n_new_nights in n_new_nights_arr:\n",
    "    outlier_cols_list.append(night_mag_string.format(n_new_nights))\n",
    "    outlier_cols_list.append(night_std_string.format(n_new_nights))\n",
    "\n",
    "# TODO include this in function for initialising the output Adler DB\n",
    "sql_outlier_cols = \"\"\n",
    "for col in outlier_cols_list:\n",
    "    sql_outlier_cols += f\", {col} INTEGER\"\n",
    "\n",
    "adler_flags_create_sql = f\"CREATE TABLE AdlerSourceFlags(ssObjectId TEXT, filter_name TEXT, diaSourceId TEXT, midPointMjdTai INTEGER{sql_outlier_cols})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"----------------------------------------\")\n",
    "logger.info(\"New loop started\")\n",
    "logger.info(\"----------------------------------------\")\n",
    "\n",
    "# process_mjd_arr = np.arange(min_obstime_mjd-0.5, max_obstime_mjd+1.5, 1)\n",
    "# process_mjd_arr = np.arange(60795.5, 60799.5, 1)\n",
    "process_mjd_arr = np.array([60799.5])\n",
    "\n",
    "for process_mjd in process_mjd_arr:\n",
    "    process_date = mjd_to_utc(process_mjd)\n",
    "    start_of_night = mjd_to_utc(process_mjd - 1)\n",
    "\n",
    "    # Get list of objects with observations from most recent night preceding the process date\n",
    "    # obj_df = pd.read_sql_query(f\"SELECT DISTINCT provid FROM obs_sbn WHERE obstime BETWEEN '{start_of_night}' AND '{process_date}' LIMIT 20\", input_conn)\n",
    "    obj_df = pd.read_sql_query(\n",
    "        f\"SELECT DISTINCT provid FROM obs_sbn WHERE obstime BETWEEN '{start_of_night}' AND '{process_date}'\",\n",
    "        input_conn,\n",
    "    )\n",
    "    unique_obj_ids = obj_df.provid.to_numpy()\n",
    "    logger.info(f\"{len(unique_obj_ids)} objects to analyze\")\n",
    "\n",
    "    if len(unique_obj_ids) == 0:\n",
    "        logger.info(f\"No objects to process for {process_mjd}\")\n",
    "        continue\n",
    "\n",
    "    output_dir = f\"outputs_lesscols_update_full_{process_mjd}\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    adler_output_filename = f\"{output_dir}/adler_output.sqlite\"\n",
    "    conn_adler_out = sqlite3.connect(adler_output_filename)\n",
    "\n",
    "    # TODO tidy this up into function\n",
    "    cur_adler_out = conn_adler_out.cursor()\n",
    "\n",
    "    cur_adler_out.execute(\"DROP TABLE IF EXISTS AdlerData;\")\n",
    "    cur_adler_out.execute(\"DROP TABLE IF EXISTS  AdlerSourceFlags;\")\n",
    "\n",
    "    cur_adler_out.execute(\"CREATE TABLE AdlerData(ssObjectId TEXT, timestamp REAL, PRIMARY KEY (ssObjectId))\")\n",
    "    # added creation of AdlerSourceFlags table\n",
    "    cur_adler_out.execute(adler_flags_create_sql)\n",
    "\n",
    "    for obj_id in tqdm(unique_obj_ids, desc=f\"Objects to process for {process_mjd}\"):\n",
    "        # Taking all data, no time constraint\n",
    "        planetoid = AdlerPlanetoid.construct_from_mpc_obs_sbn(\n",
    "            ssObjectId=obj_id,\n",
    "            sql_filename=input_rubin_sql_file,\n",
    "            filter_list=filter_list,\n",
    "            date_range=[process_mjd - data_timespan, process_mjd],\n",
    "        )\n",
    "\n",
    "        adler_data = AdlerData(obj_id, planetoid.filter_list)\n",
    "\n",
    "        for filt in planetoid.filter_list:\n",
    "            df_obs = sci_utils.get_df_obs_filt(planetoid, filt=filt)\n",
    "\n",
    "            # Initialise outlier columns in df_obs\n",
    "            # TODO Consider how we'll load in previous flags if an existing Adler DB is provided\n",
    "            for col in outlier_cols_list:\n",
    "                # Populate outlier columns with zeros\n",
    "                df_obs[col] = np.zeros(shape=len(df_obs), dtype=int)\n",
    "\n",
    "            # TODO this may change as no longer checking how many datapoints from previous process\n",
    "            nobs_nomask = len(df_obs)\n",
    "\n",
    "            err_flag = df_obs.magErr.isnull().all()\n",
    "            if err_flag:\n",
    "                logger.info(\"All magErr values are NaNs, proceed with caution\")\n",
    "            else:\n",
    "                # Remove observations with large errorbars\n",
    "                magErr_percentile_cut = 95  # Value (between 0 and 100) to define the percentile above which we cut data with large magErr values\n",
    "                magErr_mask = df_obs.magErr <= np.nanpercentile(df_obs.magErr, q=magErr_percentile_cut)\n",
    "                df_obs = df_obs[magErr_mask]\n",
    "\n",
    "            for n_new_nights in n_new_nights_arr:\n",
    "                # Split into previous observations and observations from the most recent night(s)\n",
    "                mask = df_obs[\"midPointMjdTai\"] < process_mjd - n_new_nights\n",
    "\n",
    "                df_obs_old = df_obs[mask].copy()\n",
    "                df_obs_new = df_obs[~mask].copy()\n",
    "                logger.info(\"Previous observations (date < {}): {}\".format(process_mjd - 1, len(df_obs_old)))\n",
    "                logger.info(\n",
    "                    \"New observations ({} <= date < {}): {}\".format(\n",
    "                        process_mjd - 1, process_mjd, len(df_obs_new)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if len(df_obs_old) < 2:\n",
    "                    # Taken from adler_demo.py\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "                if len(df_obs_new) == 0:\n",
    "                    logger.info(f\"No new observations in {filt}, continuing to next band/object\")\n",
    "                    continue\n",
    "\n",
    "                # TODO consider how this affects writing out to AdlerData (possibly fine with how it's already setup)\n",
    "                sig_clip_mask = astropy_sigma_clip(df_obs_old[mag_col], sigma=sig_clip_val).mask\n",
    "\n",
    "                df_obs_old = df_obs_old[~sig_clip_mask].copy()\n",
    "\n",
    "                if len(df_obs_old) < 2:\n",
    "                    # Taken from adler_demo.py\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations after sigma clipping, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                median_mag = np.median(df_obs_old[mag_col])\n",
    "                # TODO consider storing relevant res values\n",
    "                res = np.array(df_obs_new[mag_col]) - median_mag\n",
    "\n",
    "                for diff_cut in diff_cuts_arr:\n",
    "                    diff_cut_outlier_arr = sci_utils.outlier_diff(res, diff_cut=diff_cut)\n",
    "                    # Populate outlier rows with True returned by outlier_diff with the current diff_cut value\n",
    "                    df_obs_new.loc[diff_cut_outlier_arr, night_mag_string.format(n_new_nights)] = diff_cut\n",
    "\n",
    "                std_cut_outlier_arr = [False] * len(df_obs_new)\n",
    "                if len(df_obs_old) < 4:\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations to check with outlier_sigma_diff\"\n",
    "                    )\n",
    "                    # TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "                else:\n",
    "                    if err_flag:\n",
    "                        logger.info(f\"No measurement errors, can't attempt outlier_sigma_diff\")\n",
    "                        # TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "                    else:\n",
    "                        for std_cut in std_cuts_arr:\n",
    "                            std_cut_outlier_arr = sci_utils.outlier_sigma_diff(\n",
    "                                res, df_obs_new[magErr_col], std_sigma=std_cut\n",
    "                            )\n",
    "                            df_obs_new.loc[std_cut_outlier_arr, night_std_string.format(n_new_nights)] = (\n",
    "                                std_cut\n",
    "                            )\n",
    "\n",
    "                if make_plots:\n",
    "                    # Identify any outliers detected\n",
    "                    tmp_master_outlier_flag = (diff_cut_outlier_arr) | (std_cut_outlier_arr)\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.errorbar(\n",
    "                        df_obs_old[\"midPointMjdTai\"],\n",
    "                        df_obs_old[mag_col],\n",
    "                        df_obs_old[magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\".\",\n",
    "                        color=\"k\",\n",
    "                        label=\"Previous observations\",\n",
    "                    )\n",
    "                    ax.errorbar(\n",
    "                        df_obs_new[\"midPointMjdTai\"],\n",
    "                        df_obs_new[mag_col],\n",
    "                        df_obs_new[magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\".\",\n",
    "                        color=\"c\",\n",
    "                        label=\"New observations\",\n",
    "                    )\n",
    "                    ax.errorbar(\n",
    "                        df_obs_new[tmp_master_outlier_flag][\"midPointMjdTai\"],\n",
    "                        df_obs_new[tmp_master_outlier_flag][mag_col],\n",
    "                        df_obs_new[tmp_master_outlier_flag][magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\"x\",\n",
    "                        color=\"b\",\n",
    "                        label=\"Outliers\",\n",
    "                    )\n",
    "                    ax.axhline(median_mag)\n",
    "                    ax.invert_yaxis()\n",
    "                    ax.set_xlabel(\"Time [MJD]\")\n",
    "                    ax.set_ylabel(f\"{filt}-band Reduced Magnitude\")\n",
    "                    fig.savefig(\n",
    "                        f\"{output_dir}/{obj_id}_{filt}_{n_new_nights}nights_outliers.png\",\n",
    "                        bbox_inches=\"tight\",\n",
    "                        pad_inches=0.05,\n",
    "                    )\n",
    "                    plt.close(fig)\n",
    "\n",
    "                # Use pandas.DataFrame.update to add the outlier flags to the df_obs DataFrame\n",
    "                df_obs.update(df_obs_new)\n",
    "\n",
    "            # Identify rows that contain at least 1 outlier flag set to a value greater than 0\n",
    "            master_outlier_flag = df_obs[outlier_cols_list].any(axis=1)\n",
    "            df_obs.loc[\n",
    "                master_outlier_flag,\n",
    "                [\"ssObjectId\", \"filter_name\", \"diaSourceId\", \"midPointMjdTai\"] + outlier_cols_list,\n",
    "            ].to_sql(\"AdlerSourceFlags\", con=conn_adler_out, if_exists=\"append\", index=False)\n",
    "\n",
    "            # TODO consider how to include check and flag for if outliers span multiple consecutive nights\n",
    "            # Perhaps this is easier now we update df_obs\n",
    "            # Some kind of resetting cumulative sum to test for sustained outliers that then looks for any value above say 3. [0,1,0,1,2,0] gives [0,1,0,1,3,0]\n",
    "\n",
    "            # Write nobs to AdlerData\n",
    "            # TODO write median and standard deviation of previous observations to AdlerData\n",
    "            # Create AdlerData structure to do the above where we have a particular model that is designed for the median\n",
    "            adler_data.populate_phase_parameters(filt, **{\"nobs\": nobs_nomask})\n",
    "            adler_data.write_row_to_database(adler_output_filename)\n",
    "\n",
    "            logger.info(f\"New information for {obj_id} written to AdlerSourceFlags and AdlerData tables\")\n",
    "\n",
    "    # TODO make summary stats a function\n",
    "    logger.info(f\"Computing summary statistics for {process_mjd}\")\n",
    "\n",
    "    cur_adler_out.execute(\"SELECT COUNT(*) FROM AdlerData\")\n",
    "    n_obj_analzyed = cur_adler_out.fetchall()[0][0]\n",
    "    logger.info(f\"Number of objects analysed: {n_obj_analzyed}\")\n",
    "\n",
    "    # Get column information to check what filters have previously been analysed (and therefore have {filter}_nobs columns in AdlerData)\n",
    "    cur_adler_out.execute(\"PRAGMA table_info(AdlerData);\")\n",
    "    adler_out_cols = [row[1] for row in cur_adler_out.fetchall()]\n",
    "    filter_nobs_columns = [c for c in adler_out_cols if c.endswith(\"_nobs\")]\n",
    "    current_adlerdata_filters = [c.replace(\"_nobs\", \"\") for c in filter_nobs_columns]\n",
    "\n",
    "    # #Manually removing u filter because it has so few observations in comparison\n",
    "    # filter_nobs_columns.remove('u_nobs')\n",
    "\n",
    "    filter_columns_sql = \", \".join(filter_nobs_columns)\n",
    "    nobs_df = pd.read_sql_query(f\"SELECT ssObjectId, {filter_columns_sql} FROM AdlerData\", conn_adler_out)\n",
    "\n",
    "    for band in current_adlerdata_filters:\n",
    "        med_obs_band = np.median(nobs_df[f\"{band}_nobs\"])\n",
    "        std_obs_band = np.std(nobs_df[f\"{band}_nobs\"])\n",
    "        sum_obs_band = np.sum(nobs_df[f\"{band}_nobs\"])\n",
    "\n",
    "        logger.info(f\"Total number of observations for {band}-band: {sum_obs_band}\")\n",
    "        logger.info(\n",
    "            f\"Observations per object for {band}-band: Median={med_obs_band}, standard deviation={std_obs_band}\"\n",
    "        )\n",
    "\n",
    "    filters_to_plot = [\"g\", \"r\", \"i\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(\n",
    "        (nobs_df[\"g_nobs\"], nobs_df[\"r_nobs\"], nobs_df[\"i_nobs\"]),\n",
    "        color=[plot_filter_colors_white_background[filt] for filt in filters_to_plot],\n",
    "        label=[f\"{filt}-band\" for filt in filters_to_plot],\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Observations per filter\")\n",
    "    ax.set_ylabel(\"Number of objects\")\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{output_dir}/obs_per_band_hists.png\", bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.close(fig)\n",
    "    logger.info(\n",
    "        f\"Histograms of observations per band per object saved to {output_dir}/obs_per_band_hists.png\"\n",
    "    )\n",
    "\n",
    "    for n_new_nights in n_new_nights_arr:\n",
    "        logger.info(\n",
    "            f\"Checking for number of outliers when considering last {n_new_nights} night(s) as new observations\"\n",
    "        )\n",
    "        for diff_cut in diff_cuts_arr:\n",
    "            cur_adler_out.execute(\n",
    "                f\"SELECT COUNT(*) FROM AdlerSourceFlags WHERE {night_mag_string.format(n_new_nights)}>={diff_cut}\"\n",
    "            )\n",
    "            logger.info(f\"Number of outliers above {diff_cut} magnitude: {cur_adler_out.fetchall()[0][0]}\")\n",
    "        for std_cut in std_cuts_arr:\n",
    "            cur_adler_out.execute(\n",
    "                f\"SELECT COUNT(*) FROM AdlerSourceFlags WHERE {night_std_string.format(n_new_nights)}>={std_cut}\"\n",
    "            )\n",
    "            logger.info(f\"Number of outliers above {std_cut}-sigma: {cur_adler_out.fetchall()[0][0]}\")\n",
    "\n",
    "    # TODO perhaps add example query to find the outliers in the output database\n",
    "\n",
    "    # TODO distribution of outliers per object and per filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06145748",
   "metadata": {},
   "source": [
    "### Interactive plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17747105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# obj_id = \"2025 MV10\"\n",
    "obj_id = \"2025 MX40\"\n",
    "process_mjd = 60799.5\n",
    "filt = \"g\"\n",
    "n_new_nights = 3\n",
    "\n",
    "#######\n",
    "\n",
    "planetoid = AdlerPlanetoid.construct_from_mpc_obs_sbn(\n",
    "    ssObjectId=obj_id,\n",
    "    sql_filename=input_rubin_sql_file,\n",
    "    filter_list=filter_list,\n",
    "    date_range=[process_mjd - data_timespan, process_mjd],\n",
    ")\n",
    "\n",
    "adler_data = AdlerData(obj_id, planetoid.filter_list)\n",
    "\n",
    "df_obs = sci_utils.get_df_obs_filt(planetoid, filt=filt)\n",
    "\n",
    "# Initialise outlier columns in df_obs\n",
    "# TODO Consider how we'll load in previous flags if an existing Adler DB is provided\n",
    "for col in outlier_cols_list:\n",
    "    # Populate outlier columns with zeros\n",
    "    df_obs[col] = np.zeros(shape=len(df_obs), dtype=int)\n",
    "\n",
    "nobs_nomask = len(df_obs)\n",
    "\n",
    "err_flag = df_obs.magErr.isnull().all()\n",
    "if err_flag:\n",
    "    logger.info(\"All magErr values are NaNs, proceed with caution\")\n",
    "else:\n",
    "    # Remove observations with large errorbars\n",
    "    magErr_percentile_cut = 95  # Value (between 0 and 100) to define the percentile above which we cut data with large magErr values\n",
    "    magErr_mask = df_obs.magErr <= np.nanpercentile(df_obs.magErr, q=magErr_percentile_cut)\n",
    "    df_obs = df_obs[magErr_mask]\n",
    "\n",
    "# Split into previous observations and observations from the most recent night(s)\n",
    "mask = df_obs[\"midPointMjdTai\"] < process_mjd - n_new_nights\n",
    "\n",
    "df_obs_old = df_obs[mask].copy()\n",
    "df_obs_new = df_obs[~mask].copy()\n",
    "logger.info(\"Previous observations (date < {}): {}\".format(process_mjd - 1, len(df_obs_old)))\n",
    "logger.info(\"New observations ({} <= date < {}): {}\".format(process_mjd - 1, process_mjd, len(df_obs_new)))\n",
    "\n",
    "# if len(df_obs_old)<2:\n",
    "#     #Taken from adler_demo.py\n",
    "#     logger.info(\"Insufficient number of previous observations, continuing to next band/object\")\n",
    "#     continue\n",
    "# if len(df_obs_new)==0:\n",
    "#     logger.info(f\"No new observations in {filt}, continuing to next band/object\")\n",
    "#     continue\n",
    "\n",
    "# TODO consider how this affects writing out to AdlerData (possibly fine with how it's already setup)\n",
    "sig_clip_mask = astropy_sigma_clip(df_obs_old[mag_col], sigma=sig_clip_val).mask\n",
    "\n",
    "df_obs_old = df_obs_old[~sig_clip_mask].copy()\n",
    "\n",
    "# if len(df_obs_old)<2:\n",
    "#     #Taken from adler_demo.py\n",
    "#     logger.info(\"Insufficient number of previous observations after sigma clipping, continuing to next band/object\")\n",
    "#     continue\n",
    "\n",
    "median_mag = np.median(df_obs_old[mag_col])\n",
    "# TODO consider storing relevant res values\n",
    "res = np.array(df_obs_new[mag_col]) - median_mag\n",
    "\n",
    "for diff_cut in diff_cuts_arr:\n",
    "    diff_cut_outlier_arr = sci_utils.outlier_diff(res, diff_cut=diff_cut)\n",
    "    # Populate outlier rows with True returned by outlier_diff with the current diff_cut value\n",
    "    df_obs_new.loc[diff_cut_outlier_arr, night_mag_string.format(n_new_nights)] = diff_cut\n",
    "\n",
    "std_cut_outlier_arr = [False] * len(df_obs_new)\n",
    "if len(df_obs_old) < 4:\n",
    "    logger.info(\"Insufficient number of previous observations to check with outlier_sigma_diff\")\n",
    "    # TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "else:\n",
    "    if err_flag:\n",
    "        logger.info(f\"No measurement errors, can't attempt outlier_sigma_diff\")\n",
    "        # TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "    else:\n",
    "        for std_cut in std_cuts_arr:\n",
    "            std_cut_outlier_arr = sci_utils.outlier_sigma_diff(res, df_obs_new[magErr_col], std_sigma=std_cut)\n",
    "            df_obs_new.loc[std_cut_outlier_arr, night_std_string.format(n_new_nights)] = std_cut\n",
    "\n",
    "%matplotlib widget\n",
    "# Identify any outliers detected\n",
    "tmp_master_outlier_flag = (diff_cut_outlier_arr) | (std_cut_outlier_arr)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.errorbar(\n",
    "    df_obs_old[\"midPointMjdTai\"],\n",
    "    df_obs_old[mag_col],\n",
    "    df_obs_old[magErr_col],\n",
    "    ls=\"\",\n",
    "    marker=\".\",\n",
    "    color=\"k\",\n",
    "    label=\"Previous observations\",\n",
    ")\n",
    "ax.errorbar(\n",
    "    df_obs_new[\"midPointMjdTai\"],\n",
    "    df_obs_new[mag_col],\n",
    "    df_obs_new[magErr_col],\n",
    "    ls=\"\",\n",
    "    marker=\".\",\n",
    "    color=\"c\",\n",
    "    label=\"New observations\",\n",
    ")\n",
    "ax.errorbar(\n",
    "    df_obs_new[tmp_master_outlier_flag][\"midPointMjdTai\"],\n",
    "    df_obs_new[tmp_master_outlier_flag][mag_col],\n",
    "    df_obs_new[tmp_master_outlier_flag][magErr_col],\n",
    "    ls=\"\",\n",
    "    marker=\"x\",\n",
    "    color=\"b\",\n",
    "    label=\"Outliers\",\n",
    ")\n",
    "ax.axhline(median_mag)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Time [MJD]\")\n",
    "ax.set_ylabel(f\"{filt}-band Reduced Magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1104e284",
   "metadata": {},
   "source": [
    "# Format taking median of new observations and old observations to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_rubin_sql_file = f\"{root_filepath}rubin_251105.sqlite\"\n",
    "input_rubin_sql_file = f\"{root_filepath}lsst-adler/tests/data/mpc_obs_sbn_testing_database.sqlite\"\n",
    "\n",
    "input_conn = sqlite3.connect(input_rubin_sql_file)\n",
    "input_cur = input_conn.cursor()\n",
    "\n",
    "# Number of days of data to retrieve (i.e. previous 30 nights)\n",
    "data_timespan = 30\n",
    "\n",
    "from tqdm import tqdm\n",
    "import adler.utilities.science_utilities as sci_utils\n",
    "import math\n",
    "\n",
    "\n",
    "# Set column to use for magnitude (we don't currently have reduced_mag populated for MPC file format)\n",
    "mag_col = \"reduced_mag\"\n",
    "magErr_col = \"magErr\"\n",
    "\n",
    "# Set filter list (only ugri present currently, very few u, but keeping in for completeness)\n",
    "filter_list = [\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"]\n",
    "# filter_list=['g', 'r', 'i']\n",
    "\n",
    "make_plots = True\n",
    "\n",
    "# TODO implement schema switching\n",
    "schema = \"MPC\"\n",
    "# schema = \"dp03_catalogs_10yr\"\n",
    "\n",
    "min_obstime_mjd = math.floor(\n",
    "    pd.read_sql_query(f\"SELECT MIN(mjd_tai) FROM obs_sbn\", input_conn).iloc[0].values[0]\n",
    ")\n",
    "max_obstime_mjd = math.ceil(\n",
    "    pd.read_sql_query(f\"SELECT MAX(mjd_tai) FROM obs_sbn\", input_conn).iloc[0].values[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdaa784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clip as astropy_sigma_clip\n",
    "\n",
    "sig_clip_val = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f045275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds for magnitude changes\n",
    "diff_cuts_arr = np.array([0, 1, 2, 3])  # 0 included due to way we currently write to the output DB\n",
    "# std_cuts_arr = np.array([3, 4, 5])\n",
    "std_cuts_arr = np.array([5, 6])\n",
    "\n",
    "# Defines how many nights to consider as \"new observations,\" allowing for the checking of \"sustained outliers/outbursts\"\n",
    "# n_new_nights_arr = np.array([3])\n",
    "\n",
    "n_new_nights = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Defined the strings that will be used as column headers and populated later\n",
    "# night_mag_string = \"outlier_{}night_mag\"\n",
    "# night_std_string = \"outlier_{}night_sigma\"\n",
    "\n",
    "# outlier_cols_list = []\n",
    "# for n_new_nights in n_new_nights_arr:\n",
    "#     outlier_cols_list.append(night_mag_string.format(n_new_nights))\n",
    "#     outlier_cols_list.append(night_std_string.format(n_new_nights))\n",
    "\n",
    "# #TODO include this in function for initialising the output Adler DB\n",
    "# sql_outlier_cols=\"\"\n",
    "# for col in outlier_cols_list:\n",
    "#     sql_outlier_cols += f\", {col} INTEGER\"\n",
    "\n",
    "# adler_flags_create_sql = f\"CREATE TABLE AdlerSourceFlags(ssObjectId TEXT, filter_name TEXT, diaSourceId TEXT, midPointMjdTai INTEGER{sql_outlier_cols})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b1a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"----------------------------------------\")\n",
    "logger.info(\"New loop started\")\n",
    "logger.info(\"----------------------------------------\")\n",
    "\n",
    "# process_mjd_arr = np.arange(min_obstime_mjd-0.5, max_obstime_mjd+1.5, 1)\n",
    "# process_mjd_arr = np.arange(60795.5, 60799.5, 1)\n",
    "process_mjd_arr = np.array([60799.5])\n",
    "\n",
    "for process_mjd in process_mjd_arr:\n",
    "    start_of_night_mjd = process_mjd - 1\n",
    "\n",
    "    # Get list of objects with observations from most recent night preceding the process date\n",
    "    # obj_df = pd.read_sql_query(f\"SELECT DISTINCT provid FROM obs_sbn WHERE obstime BETWEEN '{start_of_night}' AND '{process_date}' LIMIT 20\", input_conn)\n",
    "    obj_df = pd.read_sql_query(\n",
    "        f\"SELECT DISTINCT provid FROM obs_sbn WHERE mjd_tai BETWEEN '{start_of_night_mjd}' AND '{process_mjd}'\",\n",
    "        input_conn,\n",
    "    )\n",
    "    unique_obj_ids = obj_df.provid.to_numpy()\n",
    "    logger.info(f\"{len(unique_obj_ids)} objects to analyze\")\n",
    "\n",
    "    if len(unique_obj_ids) == 0:\n",
    "        logger.info(f\"No objects to process for {process_mjd}\")\n",
    "        continue\n",
    "\n",
    "    output_dir = f\"outputs_sustained_checks_v2_{process_mjd}\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    adler_output_filename = f\"{output_dir}/adler_output.sqlite\"\n",
    "    conn_adler_out = sqlite3.connect(adler_output_filename)\n",
    "\n",
    "    # TODO tidy this up into function\n",
    "    cur_adler_out = conn_adler_out.cursor()\n",
    "\n",
    "    cur_adler_out.execute(\"DROP TABLE IF EXISTS AdlerData;\")\n",
    "    cur_adler_out.execute(\"DROP TABLE IF EXISTS  AdlerSourceFlags;\")\n",
    "\n",
    "    # TODO make this non-manual\n",
    "    cur_adler_out.execute(\n",
    "        f\"CREATE TABLE AdlerData(ssObjectId TEXT, timestamp REAL, g_{n_new_nights}night_sustained, r_{n_new_nights}night_sustained, i_{n_new_nights}night_sustained, u_{n_new_nights}night_sustained, PRIMARY KEY (ssObjectId))\"\n",
    "    )\n",
    "    # added creation of AdlerSourceFlags table\n",
    "    # cur_adler_out.execute(adler_flags_create_sql)\n",
    "\n",
    "    for obj_id in tqdm(unique_obj_ids, desc=f\"Objects to process for {process_mjd}\"):\n",
    "        # Taking all data, no time constraint\n",
    "        planetoid = AdlerPlanetoid.construct_from_mpc_obs_sbn(\n",
    "            ssObjectId=obj_id,\n",
    "            sql_filename=input_rubin_sql_file,\n",
    "            filter_list=filter_list,\n",
    "            date_range=[process_mjd - data_timespan, process_mjd],\n",
    "        )\n",
    "\n",
    "        adler_data = AdlerData(obj_id, planetoid.filter_list)\n",
    "\n",
    "        for filt in planetoid.filter_list:\n",
    "            df_obs = sci_utils.get_df_obs_filt(planetoid, filt=filt)\n",
    "\n",
    "            # Initialise outlier columns in df_obs\n",
    "            # TODO Consider how we'll load in previous flags if an existing Adler DB is provided\n",
    "            # for col in outlier_cols_list:\n",
    "            #     #Populate outlier columns with zeros\n",
    "            #     df_obs[col] = np.zeros(shape=len(df_obs), dtype=int)\n",
    "\n",
    "            # TODO this may change as no longer checking how many datapoints from previous process\n",
    "            nobs_nomask = len(df_obs)\n",
    "\n",
    "            err_flag = df_obs.magErr.isnull().all()\n",
    "            if err_flag:\n",
    "                logger.info(\"All magErr values are NaNs, proceed with caution\")\n",
    "            else:\n",
    "                # Remove observations with large errorbars\n",
    "                magErr_percentile_cut = 95  # Value (between 0 and 100) to define the percentile above which we cut data with large magErr values\n",
    "                magErr_mask = df_obs.magErr <= np.nanpercentile(df_obs.magErr, q=magErr_percentile_cut)\n",
    "                df_obs = df_obs[magErr_mask]\n",
    "\n",
    "            # for n_new_nights in n_new_nights_arr:\n",
    "            # Split into previous observations and observations from the most recent night(s)\n",
    "            mask = df_obs[\"midPointMjdTai\"] < process_mjd - n_new_nights\n",
    "\n",
    "            # TODO update the splitting and checking of previous nights (at least 2 nights in previous 3-5 nights to do sustained check\n",
    "            df_obs_old = df_obs[mask].copy()\n",
    "            df_obs_new = df_obs[~mask].copy()\n",
    "            logger.info(\"Previous observations (date < {}): {}\".format(process_mjd - 1, len(df_obs_old)))\n",
    "            logger.info(\n",
    "                \"New observations ({} <= date < {}): {}\".format(process_mjd - 1, process_mjd, len(df_obs_new))\n",
    "            )\n",
    "\n",
    "            if len(df_obs_old) < 2:\n",
    "                # Taken from adler_demo.py\n",
    "                logger.info(\"Insufficient number of previous observations, continuing to next band/object\")\n",
    "                continue\n",
    "            if len(df_obs_new) == 0:\n",
    "                logger.info(f\"No new observations in {filt}, continuing to next band/object\")\n",
    "                continue\n",
    "\n",
    "            df_obs_new.sort_values(by=\"midPointMjdTai\", inplace=True)\n",
    "\n",
    "            time_gaps = sci_utils.apparition_gap_finder(df_obs_new.midPointMjdTai.to_numpy(), dx=0.5)\n",
    "            if len(time_gaps) == 0:\n",
    "                # If there is only one night of new data, we continue to the next band/object\n",
    "                logger.info(\n",
    "                    \"Insufficient number of nights with new observations, continuing to next band/object\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # TODO consider how this affects writing out to AdlerData (possibly fine with how it's already setup)\n",
    "            sig_clip_mask = astropy_sigma_clip(df_obs_old[mag_col], sigma=sig_clip_val).mask\n",
    "\n",
    "            df_obs_old = df_obs_old[~sig_clip_mask].copy()\n",
    "\n",
    "            sig_clip_mask = astropy_sigma_clip(df_obs_new[mag_col], sigma=sig_clip_val).mask\n",
    "\n",
    "            df_obs_new = df_obs_new[~sig_clip_mask].copy()\n",
    "\n",
    "            if len(df_obs_old) < 2:\n",
    "                # Taken from adler_demo.py\n",
    "                logger.info(\n",
    "                    \"Insufficient number of previous observations after sigma clipping, continuing to next band/object\"\n",
    "                )\n",
    "                continue\n",
    "            if len(df_obs_new) == 0:\n",
    "                logger.info(\n",
    "                    f\"No new observations in {filt} after sigma clipping, continuing to next band/object\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            old_median_mag = np.median(df_obs_old[mag_col])\n",
    "\n",
    "            new_median_mag = np.median(df_obs_new[mag_col])\n",
    "\n",
    "            # #TODO consider storing relevant res values\n",
    "            # res = np.array(df_obs_new[mag_col]) - median_mag\n",
    "\n",
    "            diff_cut_threshold_arr = np.abs(new_median_mag - old_median_mag) > diff_cuts_arr\n",
    "\n",
    "            diff_cut_met = np.max(diff_cuts_arr[diff_cut_threshold_arr])\n",
    "\n",
    "            # TODO add columns to adlerdata (temporary version) to store these sustaine doutliers, fix the plot down below\n",
    "\n",
    "            # for diff_cut in diff_cuts_arr:\n",
    "            #     diff_cut_outlier_arr = sci_utils.outlier_diff(res, diff_cut=diff_cut)\n",
    "            #     #Populate outlier rows with True returned by outlier_diff with the current diff_cut value\n",
    "            #     df_obs_new.loc[diff_cut_outlier_arr, night_mag_string.format(n_new_nights)] = diff_cut\n",
    "\n",
    "            # std_cut_outlier_arr = [False] * len(df_obs_new)\n",
    "            # if len(df_obs_old)<4:\n",
    "            #     logger.info(\"Insufficient number of previous observations to check with outlier_sigma_diff\")\n",
    "            #     #TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "            # else:\n",
    "            #     if err_flag:\n",
    "            #         logger.info(f\"No measurement errors, can't attempt outlier_sigma_diff\")\n",
    "            #         #TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "            #     else:\n",
    "            #         for std_cut in std_cuts_arr:\n",
    "            #             std_cut_outlier_arr = sci_utils.outlier_sigma_diff(res, df_obs_new[magErr_col], std_sigma=std_cut)\n",
    "            #             df_obs_new.loc[std_cut_outlier_arr, night_std_string.format(n_new_nights)] = std_cut\n",
    "\n",
    "            if make_plots:\n",
    "                # Identify any outliers detected\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.errorbar(\n",
    "                    df_obs_old[\"midPointMjdTai\"],\n",
    "                    df_obs_old[mag_col],\n",
    "                    df_obs_old[magErr_col],\n",
    "                    ls=\"\",\n",
    "                    marker=\".\",\n",
    "                    color=\"k\",\n",
    "                    label=\"Previous observations\",\n",
    "                )\n",
    "                ax.errorbar(\n",
    "                    df_obs_new[\"midPointMjdTai\"],\n",
    "                    df_obs_new[mag_col],\n",
    "                    df_obs_new[magErr_col],\n",
    "                    ls=\"\",\n",
    "                    marker=\".\",\n",
    "                    color=\"c\",\n",
    "                    label=\"New observations\",\n",
    "                )\n",
    "                ax.axhline(old_median_mag, ls=\"--\", c=\"k\")\n",
    "                ax.axhline(new_median_mag, ls=\"--\", c=\"c\")\n",
    "                ax.invert_yaxis()\n",
    "                ax.set_xlabel(\"Time [MJD]\")\n",
    "                ax.set_ylabel(f\"{filt}-band Reduced Magnitude\")\n",
    "                fig.savefig(\n",
    "                    f\"{output_dir}/{obj_id}_{filt}_{n_new_nights}nights_outliers.png\",\n",
    "                    bbox_inches=\"tight\",\n",
    "                    pad_inches=0.05,\n",
    "                )\n",
    "                plt.close(fig)\n",
    "\n",
    "                # #Use pandas.DataFrame.update to add the outlier flags to the df_obs DataFrame\n",
    "                # df_obs.update(df_obs_new)\n",
    "\n",
    "            # Identify rows that contain at least 1 outlier flag set to a value greater than 0\n",
    "            # master_outlier_flag = df_obs[outlier_cols_list].any(axis=1)\n",
    "            # df_obs.loc[master_outlier_flag,['ssObjectId', 'filter_name', 'diaSourceId', 'midPointMjdTai'] + outlier_cols_list].to_sql('AdlerSourceFlags', con=conn_adler_out, if_exists='append', index=False)\n",
    "\n",
    "            # TODO consider how to include check and flag for if outliers span multiple consecutive nights\n",
    "            # Perhaps this is easier now we update df_obs\n",
    "            # Some kind of resetting cumulative sum to test for sustained outliers that then looks for any value above say 3. [0,1,0,1,2,0] gives [0,1,0,1,3,0]\n",
    "\n",
    "            # Write nobs to AdlerData\n",
    "            # TODO write median and standard deviation of previous observations to AdlerData\n",
    "            # Create AdlerData structure to do the above where we have a particular model that is designed for the median\n",
    "            adler_data.populate_phase_parameters(filt, **{\"nobs\": nobs_nomask})\n",
    "            adler_data.write_row_to_database(adler_output_filename)\n",
    "\n",
    "            cur_adler_out.execute(\n",
    "                f\"UPDATE AdlerData SET {filt}_{n_new_nights}night_sustained = {diff_cut_met} WHERE ssObjectId='{obj_id}'\"\n",
    "            )\n",
    "            conn_adler_out.commit()\n",
    "\n",
    "            logger.info(f\"New information for {obj_id} written to AdlerSourceFlags and AdlerData tables\")\n",
    "\n",
    "    # TODO make summary stats a function\n",
    "    # logger.info(f\"Computing summary statistics for {process_mjd}\")\n",
    "\n",
    "    # cur_adler_out.execute(\"SELECT COUNT(*) FROM AdlerData\")\n",
    "    # n_obj_analzyed = cur_adler_out.fetchall()[0][0]\n",
    "    # logger.info(f\"Number of objects analysed: {n_obj_analzyed}\")\n",
    "\n",
    "    # # Get column information to check what filters have previously been analysed (and therefore have {filter}_nobs columns in AdlerData)\n",
    "    # cur_adler_out.execute(\"PRAGMA table_info(AdlerData);\")\n",
    "    # adler_out_cols = [row[1] for row in cur_adler_out.fetchall()]\n",
    "    # filter_nobs_columns = [c for c in adler_out_cols if c.endswith('_nobs')]\n",
    "    # current_adlerdata_filters = [c.replace('_nobs', '') for c in filter_nobs_columns]\n",
    "\n",
    "    # # #Manually removing u filter because it has so few observations in comparison\n",
    "    # # filter_nobs_columns.remove('u_nobs')\n",
    "\n",
    "    # filter_columns_sql = ', '.join(filter_nobs_columns)\n",
    "    # nobs_df = pd.read_sql_query(f\"SELECT ssObjectId, {filter_columns_sql} FROM AdlerData\", conn_adler_out)\n",
    "\n",
    "    # for band in current_adlerdata_filters:\n",
    "    #     med_obs_band = np.median(nobs_df[f\"{band}_nobs\"])\n",
    "    #     std_obs_band = np.std(nobs_df[f\"{band}_nobs\"])\n",
    "    #     sum_obs_band = np.sum(nobs_df[f\"{band}_nobs\"])\n",
    "\n",
    "    #     logger.info(f\"Total number of observations for {band}-band: {sum_obs_band}\")\n",
    "    #     logger.info(f\"Observations per object for {band}-band: Median={med_obs_band}, standard deviation={std_obs_band}\")\n",
    "\n",
    "    # filters_to_plot = ['g', 'r', 'i']\n",
    "    # fig, ax= plt.subplots()\n",
    "    # ax.hist((nobs_df['g_nobs'], nobs_df['r_nobs'], nobs_df['i_nobs']),\n",
    "    #         color=[plot_filter_colors_white_background[filt] for filt in filters_to_plot],\n",
    "    #         label=[f\"{filt}-band\" for filt in filters_to_plot])\n",
    "\n",
    "    # ax.set_xlabel(\"Observations per filter\")\n",
    "    # ax.set_ylabel(\"Number of objects\")\n",
    "    # ax.legend()\n",
    "    # fig.savefig(f\"{output_dir}/obs_per_band_hists.png\", bbox_inches='tight', pad_inches=0.05)\n",
    "    # plt.close(fig)\n",
    "    # logger.info(f\"Histograms of observations per band per object saved to {output_dir}/obs_per_band_hists.png\")\n",
    "\n",
    "    # for n_new_nights in n_new_nights_arr:\n",
    "    #     logger.info(f\"Checking for number of outliers when considering last {n_new_nights} night(s) as new observations\")\n",
    "    #     for diff_cut in diff_cuts_arr:\n",
    "    #         cur_adler_out.execute(f\"SELECT COUNT(*) FROM AdlerSourceFlags WHERE {night_mag_string.format(n_new_nights)}>={diff_cut}\")\n",
    "    #         logger.info(f\"Number of outliers above {diff_cut} magnitude: {cur_adler_out.fetchall()[0][0]}\")\n",
    "    #     for std_cut in std_cuts_arr:\n",
    "    #         cur_adler_out.execute(f\"SELECT COUNT(*) FROM AdlerSourceFlags WHERE {night_std_string.format(n_new_nights)}>={std_cut}\")\n",
    "    #         logger.info(f\"Number of outliers above {std_cut}-sigma: {cur_adler_out.fetchall()[0][0]}\")\n",
    "\n",
    "    # #TODO perhaps add example query to find the outliers in the output database\n",
    "\n",
    "    # #TODO distribution of outliers per object and per filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa88e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb0321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db6956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c78cbc0",
   "metadata": {},
   "source": [
    "# Trying to use new class structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fbe8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"----------------------------------------\")\n",
    "logger.info(\"New loop started\")\n",
    "logger.info(\"----------------------------------------\")\n",
    "\n",
    "# process_mjd_arr = np.arange(min_obstime_mjd-0.5, max_obstime_mjd+1.5, 1)\n",
    "# process_mjd_arr = np.arange(60795.5, 60799.5, 1)\n",
    "process_mjd_arr = np.array([60799.5])\n",
    "\n",
    "for process_mjd in process_mjd_arr:\n",
    "    process_date = mjd_to_utc(process_mjd)\n",
    "    start_of_night = mjd_to_utc(process_mjd - 1)\n",
    "\n",
    "    # Get list of objects with observations from most recent night preceding the process date\n",
    "    # obj_df = pd.read_sql_query(f\"SELECT DISTINCT provid FROM obs_sbn WHERE obstime BETWEEN '{start_of_night}' AND '{process_date}' LIMIT 20\", input_conn)\n",
    "    obj_df = pd.read_sql_query(\n",
    "        f\"SELECT DISTINCT provid FROM obs_sbn WHERE obstime BETWEEN '{start_of_night}' AND '{process_date}'\",\n",
    "        input_conn,\n",
    "    )\n",
    "    unique_obj_ids = obj_df.provid.to_numpy()\n",
    "    logger.info(f\"{len(unique_obj_ids)} objects to analyze\")\n",
    "\n",
    "    if len(unique_obj_ids) == 0:\n",
    "        logger.info(f\"No objects to process for {process_mjd}\")\n",
    "        continue\n",
    "\n",
    "    output_dir = f\"outputs_lesscols_update_full_{process_mjd}\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    adler_output_filename = f\"{output_dir}/adler_output.sqlite\"\n",
    "    conn_adler_out = sqlite3.connect(adler_output_filename)\n",
    "\n",
    "    # TODO tidy this up into function\n",
    "    cur_adler_out = conn_adler_out.cursor()\n",
    "\n",
    "    cur_adler_out.execute(\"DROP TABLE IF EXISTS AdlerData;\")\n",
    "    cur_adler_out.execute(\"DROP TABLE IF EXISTS  AdlerSourceFlags;\")\n",
    "\n",
    "    cur_adler_out.execute(\"CREATE TABLE AdlerData(ssObjectId TEXT, timestamp REAL, PRIMARY KEY (ssObjectId))\")\n",
    "    # added creation of AdlerSourceFlags table\n",
    "    cur_adler_out.execute(adler_flags_create_sql)\n",
    "\n",
    "    for obj_id in tqdm(unique_obj_ids, desc=f\"Objects to process for {process_mjd}\"):\n",
    "        # Taking all data, no time constraint\n",
    "        planetoid = AdlerPlanetoid.construct_from_mpc_obs_sbn(\n",
    "            ssObjectId=obj_id,\n",
    "            sql_filename=input_rubin_sql_file,\n",
    "            filter_list=filter_list,\n",
    "            date_range=[process_mjd - data_timespan, process_mjd],\n",
    "        )\n",
    "\n",
    "        adler_data = AdlerData(obj_id, planetoid.filter_list)\n",
    "\n",
    "        for filt in planetoid.filter_list:\n",
    "            df_obs = sci_utils.get_df_obs_filt(planetoid, filt=filt)\n",
    "\n",
    "            # Initialise outlier columns in df_obs\n",
    "            # TODO Consider how we'll load in previous flags if an existing Adler DB is provided\n",
    "            for col in outlier_cols_list:\n",
    "                # Populate outlier columns with zeros\n",
    "                df_obs[col] = np.zeros(shape=len(df_obs), dtype=int)\n",
    "\n",
    "            # TODO this may change as no longer checking how many datapoints from previous process\n",
    "            nobs_nomask = len(df_obs)\n",
    "\n",
    "            err_flag = df_obs.magErr.isnull().all()\n",
    "            if err_flag:\n",
    "                logger.info(\"All magErr values are NaNs, proceed with caution\")\n",
    "            else:\n",
    "                # Remove observations with large errorbars\n",
    "                magErr_percentile_cut = 95  # Value (between 0 and 100) to define the percentile above which we cut data with large magErr values\n",
    "                magErr_mask = df_obs.magErr <= np.nanpercentile(df_obs.magErr, q=magErr_percentile_cut)\n",
    "                df_obs = df_obs[magErr_mask]\n",
    "\n",
    "            for n_new_nights in n_new_nights_arr:\n",
    "                # Split into previous observations and observations from the most recent night(s)\n",
    "                mask = df_obs[\"midPointMjdTai\"] < process_mjd - n_new_nights\n",
    "\n",
    "                df_obs_old = df_obs[mask].copy()\n",
    "                df_obs_new = df_obs[~mask].copy()\n",
    "                logger.info(\"Previous observations (date < {}): {}\".format(process_mjd - 1, len(df_obs_old)))\n",
    "                logger.info(\n",
    "                    \"New observations ({} <= date < {}): {}\".format(\n",
    "                        process_mjd - 1, process_mjd, len(df_obs_new)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                if len(df_obs_old) < 2:\n",
    "                    # Taken from adler_demo.py\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "                if len(df_obs_new) == 0:\n",
    "                    logger.info(f\"No new observations in {filt}, continuing to next band/object\")\n",
    "                    continue\n",
    "\n",
    "                # TODO consider how this affects writing out to AdlerData (possibly fine with how it's already setup)\n",
    "                sig_clip_mask = astropy_sigma_clip(df_obs_old[mag_col], sigma=sig_clip_val).mask\n",
    "\n",
    "                df_obs_old = df_obs_old[~sig_clip_mask].copy()\n",
    "\n",
    "                if len(df_obs_old) < 2:\n",
    "                    # Taken from adler_demo.py\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations after sigma clipping, continuing to next band/object\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                median_mag = np.median(df_obs_old[mag_col])\n",
    "                # TODO consider storing relevant res values\n",
    "                res = np.array(df_obs_new[mag_col]) - median_mag\n",
    "\n",
    "                for diff_cut in diff_cuts_arr:\n",
    "                    diff_cut_outlier_arr = sci_utils.outlier_diff(res, diff_cut=diff_cut)\n",
    "                    # Populate outlier rows with True returned by outlier_diff with the current diff_cut value\n",
    "                    df_obs_new.loc[diff_cut_outlier_arr, night_mag_string.format(n_new_nights)] = diff_cut\n",
    "\n",
    "                std_cut_outlier_arr = [False] * len(df_obs_new)\n",
    "                if len(df_obs_old) < 4:\n",
    "                    logger.info(\n",
    "                        \"Insufficient number of previous observations to check with outlier_sigma_diff\"\n",
    "                    )\n",
    "                    # TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "                else:\n",
    "                    if err_flag:\n",
    "                        logger.info(f\"No measurement errors, can't attempt outlier_sigma_diff\")\n",
    "                        # TODO how to handle this case (i.e. do we populate the columns with something other than False?)\n",
    "                    else:\n",
    "                        for std_cut in std_cuts_arr:\n",
    "                            std_cut_outlier_arr = sci_utils.outlier_sigma_diff(\n",
    "                                res, df_obs_new[magErr_col], std_sigma=std_cut\n",
    "                            )\n",
    "                            df_obs_new.loc[std_cut_outlier_arr, night_std_string.format(n_new_nights)] = (\n",
    "                                std_cut\n",
    "                            )\n",
    "\n",
    "                if make_plots:\n",
    "                    # Identify any outliers detected\n",
    "                    tmp_master_outlier_flag = (diff_cut_outlier_arr) | (std_cut_outlier_arr)\n",
    "                    fig, ax = plt.subplots()\n",
    "                    ax.errorbar(\n",
    "                        df_obs_old[\"midPointMjdTai\"],\n",
    "                        df_obs_old[mag_col],\n",
    "                        df_obs_old[magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\".\",\n",
    "                        color=\"k\",\n",
    "                        label=\"Previous observations\",\n",
    "                    )\n",
    "                    ax.errorbar(\n",
    "                        df_obs_new[\"midPointMjdTai\"],\n",
    "                        df_obs_new[mag_col],\n",
    "                        df_obs_new[magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\".\",\n",
    "                        color=\"c\",\n",
    "                        label=\"New observations\",\n",
    "                    )\n",
    "                    ax.errorbar(\n",
    "                        df_obs_new[tmp_master_outlier_flag][\"midPointMjdTai\"],\n",
    "                        df_obs_new[tmp_master_outlier_flag][mag_col],\n",
    "                        df_obs_new[tmp_master_outlier_flag][magErr_col],\n",
    "                        ls=\"\",\n",
    "                        marker=\"x\",\n",
    "                        color=\"b\",\n",
    "                        label=\"Outliers\",\n",
    "                    )\n",
    "                    ax.axhline(median_mag)\n",
    "                    ax.invert_yaxis()\n",
    "                    ax.set_xlabel(\"Time [MJD]\")\n",
    "                    ax.set_ylabel(f\"{filt}-band Reduced Magnitude\")\n",
    "                    fig.savefig(\n",
    "                        f\"{output_dir}/{obj_id}_{filt}_{n_new_nights}nights_outliers.png\",\n",
    "                        bbox_inches=\"tight\",\n",
    "                        pad_inches=0.05,\n",
    "                    )\n",
    "                    plt.close(fig)\n",
    "\n",
    "                # Use pandas.DataFrame.update to add the outlier flags to the df_obs DataFrame\n",
    "                df_obs.update(df_obs_new)\n",
    "\n",
    "            # Identify rows that contain at least 1 outlier flag set to a value greater than 0\n",
    "            master_outlier_flag = df_obs[outlier_cols_list].any(axis=1)\n",
    "            df_obs.loc[\n",
    "                master_outlier_flag,\n",
    "                [\"ssObjectId\", \"filter_name\", \"diaSourceId\", \"midPointMjdTai\"] + outlier_cols_list,\n",
    "            ].to_sql(\"AdlerSourceFlags\", con=conn_adler_out, if_exists=\"append\", index=False)\n",
    "\n",
    "            # TODO consider how to include check and flag for if outliers span multiple consecutive nights\n",
    "            # Perhaps this is easier now we update df_obs\n",
    "            # Some kind of resetting cumulative sum to test for sustained outliers that then looks for any value above say 3. [0,1,0,1,2,0] gives [0,1,0,1,3,0]\n",
    "\n",
    "            # Write nobs to AdlerData\n",
    "            # TODO write median and standard deviation of previous observations to AdlerData\n",
    "            # Create AdlerData structure to do the above where we have a particular model that is designed for the median\n",
    "            adler_data.populate_phase_parameters(filt, **{\"nobs\": nobs_nomask})\n",
    "            adler_data.write_row_to_database(adler_output_filename)\n",
    "\n",
    "            logger.info(f\"New information for {obj_id} written to AdlerSourceFlags and AdlerData tables\")\n",
    "\n",
    "    # TODO make summary stats a function\n",
    "    logger.info(f\"Computing summary statistics for {process_mjd}\")\n",
    "\n",
    "    cur_adler_out.execute(\"SELECT COUNT(*) FROM AdlerData\")\n",
    "    n_obj_analzyed = cur_adler_out.fetchall()[0][0]\n",
    "    logger.info(f\"Number of objects analysed: {n_obj_analzyed}\")\n",
    "\n",
    "    # Get column information to check what filters have previously been analysed (and therefore have {filter}_nobs columns in AdlerData)\n",
    "    cur_adler_out.execute(\"PRAGMA table_info(AdlerData);\")\n",
    "    adler_out_cols = [row[1] for row in cur_adler_out.fetchall()]\n",
    "    filter_nobs_columns = [c for c in adler_out_cols if c.endswith(\"_nobs\")]\n",
    "    current_adlerdata_filters = [c.replace(\"_nobs\", \"\") for c in filter_nobs_columns]\n",
    "\n",
    "    # #Manually removing u filter because it has so few observations in comparison\n",
    "    # filter_nobs_columns.remove('u_nobs')\n",
    "\n",
    "    filter_columns_sql = \", \".join(filter_nobs_columns)\n",
    "    nobs_df = pd.read_sql_query(f\"SELECT ssObjectId, {filter_columns_sql} FROM AdlerData\", conn_adler_out)\n",
    "\n",
    "    for band in current_adlerdata_filters:\n",
    "        med_obs_band = np.median(nobs_df[f\"{band}_nobs\"])\n",
    "        std_obs_band = np.std(nobs_df[f\"{band}_nobs\"])\n",
    "        sum_obs_band = np.sum(nobs_df[f\"{band}_nobs\"])\n",
    "\n",
    "        logger.info(f\"Total number of observations for {band}-band: {sum_obs_band}\")\n",
    "        logger.info(\n",
    "            f\"Observations per object for {band}-band: Median={med_obs_band}, standard deviation={std_obs_band}\"\n",
    "        )\n",
    "\n",
    "    filters_to_plot = [\"g\", \"r\", \"i\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(\n",
    "        (nobs_df[\"g_nobs\"], nobs_df[\"r_nobs\"], nobs_df[\"i_nobs\"]),\n",
    "        color=[plot_filter_colors_white_background[filt] for filt in filters_to_plot],\n",
    "        label=[f\"{filt}-band\" for filt in filters_to_plot],\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Observations per filter\")\n",
    "    ax.set_ylabel(\"Number of objects\")\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{output_dir}/obs_per_band_hists.png\", bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.close(fig)\n",
    "    logger.info(\n",
    "        f\"Histograms of observations per band per object saved to {output_dir}/obs_per_band_hists.png\"\n",
    "    )\n",
    "\n",
    "    for n_new_nights in n_new_nights_arr:\n",
    "        logger.info(\n",
    "            f\"Checking for number of outliers when considering last {n_new_nights} night(s) as new observations\"\n",
    "        )\n",
    "        for diff_cut in diff_cuts_arr:\n",
    "            cur_adler_out.execute(\n",
    "                f\"SELECT COUNT(*) FROM AdlerSourceFlags WHERE {night_mag_string.format(n_new_nights)}>={diff_cut}\"\n",
    "            )\n",
    "            logger.info(f\"Number of outliers above {diff_cut} magnitude: {cur_adler_out.fetchall()[0][0]}\")\n",
    "        for std_cut in std_cuts_arr:\n",
    "            cur_adler_out.execute(\n",
    "                f\"SELECT COUNT(*) FROM AdlerSourceFlags WHERE {night_std_string.format(n_new_nights)}>={std_cut}\"\n",
    "            )\n",
    "            logger.info(f\"Number of outliers above {std_cut}-sigma: {cur_adler_out.fetchall()[0][0]}\")\n",
    "\n",
    "    # TODO perhaps add example query to find the outliers in the output database\n",
    "\n",
    "    # TODO distribution of outliers per object and per filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adler_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
